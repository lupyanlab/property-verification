---
title: "Effect of visual interference on visual knowledge"
author: "Pierce Edmiston"
output:
  html_document:
    theme: flatly
    toc: true
---

```{r, config, echo = FALSE}
library(knitr)
opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.path = "figs/",
  cache.path = ".cache/"
)

read_chunk("utils.R")
read_chunk("knowledge_type.R")
```

```{r, utils}
```

```{r, setup}
```

```{r, data}
```

```{r, error-mods, cache = TRUE}
```

```{r, error-mods-results, cache = TRUE}
results <- list(
  feat_type = report_glmer_effect(feat_type_mod, "feat_c"),
  vis_mask = report_glmer_effect(vis_mask_mod, "mask_c"),
  non_mask = report_glmer_effect(non_mask_mod, "mask_c"),
  interaction = report_glmer_effect(overall_mod, "feat_c:mask_c")
)
```

```{r, original-results, cache = TRUE}
original_results <- list(
  feat_type = report_glmer_effect(original_feat_type_mod, "feat_c"),
  vis_mask = report_glmer_effect(original_vis_mask_mod, "mask_c"),
  non_mask = report_glmer_effect(original_non_mask_mod, "mask_c"),
  interaction = report_glmer_effect(original_mod, "feat_c:mask_c"),
  interaction_w_outliers = report_glmer_effect(original_w_outliers, "feat_c:mask_c")
)
```

```{r, replication-results, cache = TRUE}
replications <- list(
  original = report_glmer_effect(original_mod, "feat_c:mask_c"),
  replication = report_glmer_effect(replication_mod, "feat_c:mask_c"),
  preregistered = report_glmer_effect(preregistered_mod, "feat_c:mask_c")
)
```

```{r, ambiguous-results, cache = TRUE}
ambiguous <- list(
  excluded = report_glmer_effect(overall_mod, "feat_c:mask_c"),
  included = report_glmer_effect(overall_w_outliers, "feat_c:mask_c")
)
```

# Experiment runs

```{r, error-by-exp}
```

In the original sample, without visual interference, participants were just as likely to make an error on visual questions as they were on nonvisual questions, `r original_results["feat_type"]`. With visual interference, errors became significantly more likely on visual questions, `r original_results["vis_mask"]`, but not on nonvisual questions, `r original_results["non_mask"]`, resulting in a reliable _interference x question type_ interaction, `r original_results["interaction"]`. Including the ambiguous propositions did not change this interaction, `r original_results["interaction_w_outliers"]`.

When we conducted the same experiment again one year later, we failed to replicate the original findings, `r replications["replication"]`, prompting a careful review of our methods. We identified potential problems with response biases in the original design (see **Preregistered replication**, above) and also systematically removed ambiguous propositions from the set of all possible questions. We believe these slight modifications improved our chances of detecting an effect without changing our primary hypothesis. As expected, in the preregistered replication, the _interference x question type_ interaction was once again reliable and in the expected direction, `r replications["preregistered"]`.

Collapsing across all runs of the experiment supports the main conclusions drawn from the original sample and the preregistered replication. Participants were just as likely to make an error on visual questions as they were on nonvisual questions, `r results["feat_type"]`. With visual interference, errors became significantly more likely on visual questions, `r results["vis_mask"]`, but not on nonvisual questions, `r results["non_mask"]`, resulting in a marginal _interference x question type_ interaction, `r results["interaction"]`.

The impact of the ambiguous propositions is visible in **Fig. 3D**. Overall the _interference x question type_ interaction was stronger when ambiguous propositions were excluded, `r ambiguous["excluded"]`, then when they were included, `r ambiguous["included"]`. Given that the correctness of ambiguous propositions by definition cannot be determined, we excluded these propositions in the preregistered replication attempt. Without any ambiguous propositions, visual interference affects performance on visual questions only, `r replications["preregistered"]`.

```{r}
summarize_error_rates <- function(frame) {
  frame %>%
    summarize(error = error_rate(is_error)) %>%
    spread(mask_type, error)
}

question_first %>%
  group_by(feat_type, mask_type) %>%
  summarize_error_rates %>%
  select(feat_type, nomask, mask) %>%
  arrange(desc(feat_type))

question_first %>%
  group_by(exp_run_label, feat_type, mask_type) %>%
  summarize_error_rates %>%
  select(exp_run_label, feat_type, nomask, mask) %>%
  arrange(exp_run_label, desc(feat_type))
```

## Original
```{r}
tidy(original_mod, effects = "fixed")
```

## Replication
```{r}
tidy(replication_mod, effects = "fixed")
```

## Preregistered
```{r}
tidy(preregistered_mod, effects = "fixed")
```

# Overall
```{r}
tidy(overall_mod, effects = "fixed")
```

```{r, error-plot}
```

```{r, outliers}
```

# Fig. 3

```{r, fig3, fig.width = 8, fig.height = 6, dpi = 150}
```